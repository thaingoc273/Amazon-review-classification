{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Natural_Language_Processing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SpNHzkv-vzc",
        "outputId": "9a7bbdfa-7676-49a7-c6ae-ed9975492e00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XN7A9EfS_CUP",
        "outputId": "b137035b-766b-4e01-bac7-e5d6ad1b2cb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from string import punctuation\n",
        "from sklearn import svm\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "from nltk import ngrams\n",
        "from itertools import chain\n",
        "from wordcloud import WordCloud\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score, recall_score, precision_score,precision_recall_curve\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import re\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZztqAsJFQLnl"
      },
      "source": [
        "def decontract(text):\n",
        "    text = re.sub(r\"won\\'t\", \"will not\", text)\n",
        "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
        "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"\\'s\", \" is\", text)\n",
        "    text = re.sub(r\"\\'d\", \" would\", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "    text = re.sub(r\"\\'t\", \" not\", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "    text = re.sub(r\"\\'m\", \" am\", text)\n",
        "    return text"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ea3bP91OQe5I"
      },
      "source": [
        "def preprocess_text(review):\n",
        "    review = re.sub(r\"http\\S+\", \"\", review)             # removing website links\n",
        "    review = BeautifulSoup(review, 'lxml').get_text()   # removing html tags\n",
        "    review = decontract(review)                         # decontracting\n",
        "    review = re.sub(\"\\S*\\d\\S*\", \"\", review).strip()     # removing the words with numeric digits\n",
        "    review = re.sub('[^A-Za-z]+', ' ', review)          # removing non-word characters\n",
        "    review = review.lower()                             # converting to lower case\n",
        "    #review = [word for word in review.split(\" \") if not word in stop_words] # removing stop words\n",
        "    review = [lemmatizer.lemmatize(token, \"v\") for token in review] #Lemmatization\n",
        "    review = \"\".join(review)\n",
        "    review.strip()\n",
        "    return review"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGpUjrUZ_oqS"
      },
      "source": [
        "save_path = '/content/drive/My Drive/Natural Language Processing/Reviews.csv'\n",
        "df = pd.read_csv(save_path)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlOVx4b_QnUJ"
      },
      "source": [
        "df['Text'] = df['Text'].apply(lambda x:preprocess_text(x))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBdAfW91BzvH"
      },
      "source": [
        "data_set = df[[\"Text\", \"Score\"]]\n",
        "train_set, test_set = train_test_split(data_set, random_state=0)\n",
        "y_map = {0:0, 1:0, 2:0, 3:1, 4:1, 5:1}\n",
        "\n",
        "train_text = train_set[\"Text\"]\n",
        "train_score = train_set[\"Score\"].map(y_map)\n",
        "\n",
        "test_text = test_set[\"Text\"]\n",
        "test_score = test_set[\"Score\"].map(y_map)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-yq9oP8FxuC"
      },
      "source": [
        "train_set['Result'] = train_score\n",
        "df_positive = train_set[train_set[\"Result\"]==1]\n",
        "df_negative = train_set[train_set[\"Result\"]==0]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5il0GJ5QGFPZ"
      },
      "source": [
        "df_positive_text = df_positive[\"Text\"]\n",
        "df_negative_text = df_negative[\"Text\"]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd2-MJGwkZoI"
      },
      "source": [
        "df_negative_up = df_negative_text.sample(len(df_positive_text), replace=True)\n",
        "df_positive_up = df_positive_text\n",
        "df_positive_down = df_positive_text.sample(len(df_negative_text))\n",
        "df_negative_down = df_negative_text"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TS5NWy2fkf12"
      },
      "source": [
        "n=8\n",
        "df_negative_big = df_negative_text.sample(n*len(df_negative_text), replace = True)\n",
        "df_positive_big = df_positive_text.sample(n*len(df_positive_text), replace = True)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRFNF1ZhkjfD"
      },
      "source": [
        "X_big = df_positive_big.append(df_negative_big)\n",
        "y_big = np.zeros((len(X_big),1))\n",
        "l = len(df_positive_big)\n",
        "y_big[0:l] = 1"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gb1YNpD_jgFY"
      },
      "source": [
        "c = CountVectorizer(stop_words = 'english')\n",
        "tfidf_n = TfidfVectorizer(ngram_range=(1,2),stop_words = 'english')\n",
        "def text_fit(X_train, y_train, X_test, y_test, model, clf_model, coef_show=1):\n",
        "    \n",
        "    X_c = model.fit_transform(X_train)\n",
        "    \n",
        "    print('# features: {}'.format(X_c.shape[1]))\n",
        "    #X_train, X_test, y_train, y_test = train_test_split(X_c, y, random_state=0)\n",
        "    print('# train records: {}'.format(X_train.shape[0]))\n",
        "    print('# test records: {}'.format(X_test.shape[0]))\n",
        "    X_test_c = model.transform(X_test)\n",
        "    clf = clf_model.fit(X_c, y_train)\n",
        "    model_acc = clf.score(X_c, y_train)\n",
        "    print(\"Model Training Accuracy: {}\".format(model_acc))\n",
        "    pred = clf.predict(X_test_c)\n",
        "    acc = clf.score(X_test_c, y_test)\n",
        "    print ('Model Test Accuracy: {}'.format(acc))\n",
        "    confu_mat = confusion_matrix(y_test, pred)\n",
        "    print('Confusion matrix {}'.format(confu_mat))\n",
        "    f1 = f1_score(y_test, pred, pos_label=0)\n",
        "    recall_score_value = recall_score(y_test, pred, pos_label=0)\n",
        "    precision_score_value = precision_score(y_test, pred, pos_label=0)\n",
        "    print('F1 Score: {}'.format(f1))\n",
        "    print('Recall: {}'.format(recall_score_value))\n",
        "    print('Precision: {}'.format(precision_score_value))\n",
        "    if coef_show == 1: \n",
        "        w = model.get_feature_names()\n",
        "        coef = clf.coef_.tolist()[0]\n",
        "        coeff_df = pd.DataFrame({'Word' : w, 'Coefficient' : coef})\n",
        "        coeff_df = coeff_df.sort_values(['Coefficient', 'Word'], ascending=[0, 1])\n",
        "        print('')\n",
        "        print('-Top 20 positive-')\n",
        "        print(coeff_df.head(20).to_string(index=False))\n",
        "        print('')\n",
        "        print('-Top 20 negative-')        \n",
        "        print(coeff_df.tail(20).to_string(index=False))\n",
        "    "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6pXUVSWUf4v"
      },
      "source": [
        "Training With Pre-Processing Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAaAyJ6wUeW1",
        "outputId": "fa9aba07-95a2-4cc1-bc1a-dd4fd2965c0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "text_fit(train_text, train_score, test_text, test_score, c, LogisticRegression())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# features: 106996\n",
            "# train records: 426340\n",
            "# test records: 142114\n",
            "Model Training Accuracy: 0.9378829103532392\n",
            "Model Test Accuracy: 0.9237935741728471\n",
            "Confusion matrix [[ 13068   7528]\n",
            " [  3302 118216]]\n",
            "F1 Score: 0.7070280798571661\n",
            "Recall: 0.6344921343950282\n",
            "Precision: 0.7982895540623091\n",
            "\n",
            "-Top 20 positive-\n",
            "         Word  Coefficient\n",
            "     downside     3.134629\n",
            "   pleasantly     2.971120\n",
            "    addicting     2.931147\n",
            "       delish     2.468444\n",
            "    skeptical     2.430423\n",
            "       resist     2.364124\n",
            "     soothing     2.350713\n",
            "     drawback     2.313859\n",
            "      drained     2.313372\n",
            " unmistakable     2.218932\n",
            "      easiest     2.181462\n",
            "    recepient     2.181208\n",
            "      sandies     2.132267\n",
            "      worries     2.122300\n",
            "      gobbles     2.117243\n",
            " conventional     2.092833\n",
            "       hooked     2.056088\n",
            "    macademia     2.026714\n",
            "       tastey     2.008487\n",
            "        steal     2.007786\n",
            "\n",
            "-Top 20 negative-\n",
            "        Word  Coefficient\n",
            "       ruins    -2.356007\n",
            "       yikes    -2.384579\n",
            "   lethargic    -2.385725\n",
            "  discolored    -2.402720\n",
            "  unfinished    -2.407151\n",
            " disapointed    -2.410426\n",
            "     torture    -2.434203\n",
            "  unbearable    -2.446744\n",
            "         ick    -2.453217\n",
            "       worst    -2.469229\n",
            " unsatisfied    -2.516612\n",
            " undrinkable    -2.555846\n",
            "   deceptive    -2.559688\n",
            "       blech    -2.560080\n",
            "        lame    -2.595116\n",
            "     allegro    -2.612312\n",
            " embarrassed    -2.663486\n",
            "       budda    -2.722428\n",
            "     weakest    -2.861170\n",
            "      ripoff    -3.133446\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc_C1UVGcBt8",
        "outputId": "0fde46b6-666b-42c4-d345-91e9b96893cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "text_fit(train_text, train_score, test_text, test_score, tfidf_n, LogisticRegression())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# features: 3466838\n",
            "# train records: 426340\n",
            "# test records: 142114\n",
            "Model Training Accuracy: 0.950985129239574\n",
            "Model Test Accuracy: 0.9354954473169428\n",
            "Confusion matrix [[ 13351   7245]\n",
            " [  1922 119596]]\n",
            "F1 Score: 0.7444311243692325\n",
            "Recall: 0.6482326665371917\n",
            "Precision: 0.874157009101028\n",
            "\n",
            "-Top 20 positive-\n",
            "             Word  Coefficient\n",
            "            great    18.685332\n",
            "             best    16.256385\n",
            "        delicious    15.101592\n",
            "          perfect    13.376376\n",
            "            loves    12.211773\n",
            "        excellent    11.573570\n",
            "             love    11.351488\n",
            "             good    10.863352\n",
            "             nice    10.204020\n",
            "        wonderful     9.923834\n",
            "         favorite     9.736541\n",
            "          amazing     8.703701\n",
            " highly recommend     8.306376\n",
            "          awesome     8.256209\n",
            "             easy     8.184009\n",
            "            happy     7.994866\n",
            "           highly     7.875166\n",
            "            tasty     7.869253\n",
            "              bit     7.859970\n",
            "          pleased     7.533680\n",
            "\n",
            "-Top 20 negative-\n",
            "           Word  Coefficient\n",
            "           yuck    -7.694519\n",
            "    waste money    -7.703785\n",
            "          waste    -7.712976\n",
            "          gross    -7.846109\n",
            "          money    -7.965573\n",
            "          nasty    -8.013471\n",
            "           weak    -8.021510\n",
            "  unfortunately    -8.397414\n",
            "      tasteless    -8.421069\n",
            "          stale    -8.845472\n",
            "     disgusting    -9.143546\n",
            "         return    -9.187855\n",
            " disappointment    -9.406561\n",
            "          threw    -9.474790\n",
            "       horrible   -11.012016\n",
            "  disappointing   -11.323625\n",
            "   disappointed   -11.826853\n",
            "       terrible   -12.609761\n",
            "          awful   -12.610717\n",
            "          worst   -14.481923\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puBzaptvceiJ",
        "outputId": "b64dc952-243f-4267-c632-e8f308f59734",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#n=8\n",
        "text_fit(X_big, y_big, test_text, test_score, tfidf_n, LogisticRegression(max_iter = 200))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# features: 3465946\n",
            "# train records: 3410720\n",
            "# test records: 142114\n",
            "Model Training Accuracy: 0.9939857273537552\n",
            "Model Test Accuracy: 0.9498993765568488\n",
            "Confusion matrix [[ 15579   5017]\n",
            " [  2103 119415]]\n",
            "F1 Score: 0.8139923715972621\n",
            "Recall: 0.7564090114585357\n",
            "Precision: 0.8810654903291483\n",
            "\n",
            "-Top 20 positive-\n",
            "             Word  Coefficient\n",
            "            great    23.180707\n",
            "             best    21.862793\n",
            "        delicious    21.271095\n",
            "          perfect    19.766512\n",
            "        excellent    16.675352\n",
            "            loves    16.513593\n",
            " highly recommend    15.004442\n",
            "        wonderful    14.430089\n",
            "             good    14.062650\n",
            "             love    13.904756\n",
            "          amazing    13.704588\n",
            "          awesome    13.594946\n",
            "             nice    13.243553\n",
            "           hooked    13.183552\n",
            "         favorite    12.583761\n",
            "          pleased    11.852538\n",
            "            yummy    11.605677\n",
            "        fantastic    11.452121\n",
            "             glad    11.313977\n",
            "            thank    11.226202\n",
            "\n",
            "-Top 20 negative-\n",
            "           Word  Coefficient\n",
            "           weak   -10.664964\n",
            "  unfortunately   -11.091630\n",
            "           poor   -11.220509\n",
            "          gross   -11.534414\n",
            "          worse   -11.563202\n",
            "    waste money   -11.694211\n",
            "          nasty   -11.972118\n",
            "         return   -12.141820\n",
            "          stale   -12.537096\n",
            "           yuck   -12.632682\n",
            "     disgusting   -14.335795\n",
            "      tasteless   -14.464781\n",
            "          threw   -14.764441\n",
            " disappointment   -15.075079\n",
            "   disappointed   -15.191318\n",
            "       horrible   -15.264702\n",
            "  disappointing   -16.157351\n",
            "       terrible   -17.808034\n",
            "          awful   -17.886469\n",
            "          worst   -22.171303\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jq4uQtmzp7Z8",
        "outputId": "a2c27620-7d24-43b0-eeed-798ace157cee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#n=12\n",
        "text_fit(X_big, y_big, test_text, test_score, tfidf_n, LogisticRegression(max_iter = 200))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# features: 3466838\n",
            "# train records: 5116080\n",
            "# test records: 142114\n",
            "Model Training Accuracy: 0.9976800597332333\n",
            "Model Test Accuracy: 0.9508985743839453\n",
            "Confusion matrix [[ 15758   4838]\n",
            " [  2140 119378]]\n",
            "F1 Score: 0.818724996103289\n",
            "Recall: 0.7651000194212468\n",
            "Precision: 0.8804335679964241\n",
            "\n",
            "-Top 20 positive-\n",
            "             Word  Coefficient\n",
            "            great    24.965708\n",
            "             best    23.142507\n",
            "        delicious    22.638882\n",
            "          perfect    20.195739\n",
            "        excellent    17.847640\n",
            "            loves    17.177562\n",
            " highly recommend    16.242735\n",
            "        wonderful    15.391146\n",
            "             good    14.970366\n",
            "          amazing    14.424317\n",
            "           hooked    14.406410\n",
            "             nice    13.933900\n",
            "             love    13.909130\n",
            "          awesome    13.662366\n",
            "         favorite    12.947531\n",
            "          pleased    12.362464\n",
            "       just right    12.238898\n",
            "        fantastic    12.201809\n",
            "            yummy    12.031814\n",
            "            thank    11.753579\n",
            "\n",
            "-Top 20 negative-\n",
            "           Word  Coefficient\n",
            "           weak   -11.409035\n",
            "    undrinkable   -11.577876\n",
            "          worse   -11.934490\n",
            "          gross   -12.144109\n",
            "           poor   -12.176176\n",
            "          nasty   -12.475226\n",
            "         return   -12.832898\n",
            "    waste money   -13.008870\n",
            "          stale   -13.279485\n",
            "           yuck   -13.719188\n",
            "     disgusting   -14.476512\n",
            "      tasteless   -15.117211\n",
            "          threw   -15.532564\n",
            " disappointment   -15.665953\n",
            "   disappointed   -16.239427\n",
            "       horrible   -16.327091\n",
            "  disappointing   -17.624454\n",
            "          awful   -19.161973\n",
            "       terrible   -19.380100\n",
            "          worst   -22.895282\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeZsYf-4UnuK"
      },
      "source": [
        "Training without Pre-Processing Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7N61SJ6B85o",
        "outputId": "45b68537-1342-4f78-83b0-ab51997d7b0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "text_fit(train_text, train_score, test_text, test_score, c, LogisticRegression())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# features: 105762\n",
            "# train records: 426340\n",
            "# test records: 142114\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model Training Accuracy: 0.9354482338040062\n",
            "Model Test Accuracy: 0.9234347073476223\n",
            "Confusion matrix [[ 13089   7507]\n",
            " [  3374 118144]]\n",
            "F1 Score: 0.7063871124423218\n",
            "Recall: 0.6355117498543407\n",
            "Precision: 0.7950555791775497\n",
            "\n",
            "-Top 20 positive-\n",
            "         Word  Coefficient\n",
            "     downside     3.067710\n",
            "   pleasantly     2.890361\n",
            "    addicting     2.584897\n",
            "    skeptical     2.353791\n",
            "       hooked     2.244221\n",
            "       resist     2.148429\n",
            "     soothing     2.132844\n",
            "       delish     2.043792\n",
            "     drawback     1.966748\n",
            " conventional     1.959105\n",
            "      worries     1.849322\n",
            "      drained     1.847494\n",
            "      trainer     1.797404\n",
            "       brings     1.769413\n",
            "    amazingly     1.750267\n",
            "      gobbles     1.746297\n",
            "        steal     1.730062\n",
            "      easiest     1.716821\n",
            " unmistakable     1.690465\n",
            "     terrific     1.668224\n",
            "\n",
            "-Top 20 negative-\n",
            "         Word  Coefficient\n",
            "     vinegary    -2.071368\n",
            "          ick    -2.081415\n",
            " unacceptable    -2.105773\n",
            "      defeats    -2.106337\n",
            "   returnable    -2.165382\n",
            "        schar    -2.179579\n",
            "         vile    -2.187482\n",
            "      vomited    -2.202253\n",
            "  embarrassed    -2.218491\n",
            "      weakest    -2.241169\n",
            "        ruins    -2.244851\n",
            "   unbearable    -2.346018\n",
            "         lame    -2.353332\n",
            "        blech    -2.368444\n",
            "        lousy    -2.405120\n",
            "        worst    -2.407215\n",
            "  disapointed    -2.678524\n",
            "    deceptive    -2.696163\n",
            "       ripoff    -2.815729\n",
            "  undrinkable    -2.936747\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sjhF9qdaiPh",
        "outputId": "8d5dfd57-5d3d-45c1-e9f1-538789424c6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#n=8\n",
        "text_fit(X_big, y_big, test_text, test_score, tfidf_n, LogisticRegression())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# features: 3552222\n",
            "# train records: 3410720\n",
            "# test records: 142114\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model Training Accuracy: 0.991131491298025\n",
            "Model Test Accuracy: 0.9493012651814741\n",
            "Confusion matrix [[ 15700   4896]\n",
            " [  2309 119209]]\n",
            "F1 Score: 0.8133661442818287\n",
            "Recall: 0.76228393862886\n",
            "Precision: 0.8717863290576934\n",
            "\n",
            "-Top 20 positive-\n",
            "             Word  Coefficient\n",
            "             best    23.667018\n",
            "            great    23.271710\n",
            "        delicious    21.396004\n",
            "            loves    20.210369\n",
            "          perfect    18.068870\n",
            "        excellent    16.304537\n",
            "             nice    15.552418\n",
            "             love    15.050679\n",
            "           hooked    14.971249\n",
            "         favorite    14.569942\n",
            "             good    14.512067\n",
            " highly recommend    14.457361\n",
            "        wonderful    14.113683\n",
            "       just right    12.674138\n",
            "          amazing    12.526315\n",
            "             easy    12.461788\n",
            "            happy    12.453545\n",
            "            tasty    12.385956\n",
            " won disappointed    12.267151\n",
            "          awesome    12.224901\n",
            "\n",
            "-Top 20 negative-\n",
            "           Word  Coefficient\n",
            "          bland   -11.089369\n",
            "          gross   -11.560073\n",
            "          nasty   -11.645483\n",
            "    undrinkable   -11.782129\n",
            "           weak   -11.794301\n",
            "           yuck   -12.031608\n",
            "    waste money   -12.244091\n",
            "     disgusting   -12.346132\n",
            "      tasteless   -12.443127\n",
            " disappointment   -13.136874\n",
            "  unfortunately   -13.395585\n",
            "          threw   -13.853461\n",
            "          stale   -14.162244\n",
            "         return   -14.207201\n",
            "   disappointed   -14.659421\n",
            "  disappointing   -16.204768\n",
            "       horrible   -16.674934\n",
            "       terrible   -17.916726\n",
            "          awful   -18.949023\n",
            "          worst   -20.124437\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txXhciDifkJP",
        "outputId": "dae1f93f-94fe-4ba3-e9eb-1936ae79af1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#n=10\n",
        "text_fit(X_big, y_big, test_text, test_score, tfidf_n, LogisticRegression())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# features: 3552816\n",
            "# train records: 4263400\n",
            "# test records: 142114\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model Training Accuracy: 0.9889332457662898\n",
            "Model Test Accuracy: 0.94921682592848\n",
            "Confusion matrix [[ 15743   4853]\n",
            " [  2364 119154]]\n",
            "F1 Score: 0.8135286670283958\n",
            "Recall: 0.7643717226645951\n",
            "Precision: 0.869442756944828\n",
            "\n",
            "-Top 20 positive-\n",
            "             Word  Coefficient\n",
            "            great    25.784658\n",
            "             best    24.758224\n",
            "        delicious    21.221235\n",
            "            loves    19.844510\n",
            "          perfect    19.150658\n",
            "           hooked    16.830238\n",
            "             good    16.418690\n",
            " highly recommend    16.338015\n",
            "        excellent    16.170962\n",
            "             nice    14.899069\n",
            "        wonderful    14.504732\n",
            "         favorite    14.327597\n",
            "          amazing    14.292588\n",
            "          awesome    14.093606\n",
            " won disappointed    13.864424\n",
            "       just right    13.733148\n",
            "             love    13.616278\n",
            "        fantastic    13.559918\n",
            "             beat    13.375759\n",
            "            yummy    13.168810\n",
            "\n",
            "-Top 20 negative-\n",
            "           Word  Coefficient\n",
            "         ruined   -11.561902\n",
            "  great reviews   -11.564077\n",
            "          nasty   -11.851947\n",
            "    waste money   -12.861136\n",
            "  unfortunately   -12.878488\n",
            "           weak   -13.033515\n",
            "         return   -13.284527\n",
            "    undrinkable   -13.399193\n",
            "     disgusting   -13.644241\n",
            "      tasteless   -14.015133\n",
            " disappointment   -14.116759\n",
            "          stale   -14.197116\n",
            "           yuck   -14.276411\n",
            "   disappointed   -14.491683\n",
            "          threw   -15.029376\n",
            "  disappointing   -15.938680\n",
            "       horrible   -16.000093\n",
            "       terrible   -17.701771\n",
            "          awful   -17.817592\n",
            "          worst   -21.047073\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrXwrLCYnuRK",
        "outputId": "edc5e600-8e47-4a5d-965b-91e2bd52ac39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#n=14\n",
        "text_fit(X_big, y_big, test_text, test_score, tfidf_n, LogisticRegression())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# features: 3552896\n",
            "# train records: 5968760\n",
            "# test records: 142114\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model Training Accuracy: 0.992959174099813\n",
            "Model Test Accuracy: 0.9501315845025824\n",
            "Confusion matrix [[ 15973   4623]\n",
            " [  2464 119054]]\n",
            "F1 Score: 0.8184356826275203\n",
            "Recall: 0.7755389395999223\n",
            "Precision: 0.8663556977816348\n",
            "\n",
            "-Top 20 positive-\n",
            "             Word  Coefficient\n",
            "            great    30.705834\n",
            "             best    28.533700\n",
            "        delicious    24.052770\n",
            "            loves    23.517018\n",
            "          perfect    21.536202\n",
            "           hooked    20.651479\n",
            " highly recommend    18.749281\n",
            "        excellent    18.653035\n",
            "             love    18.063380\n",
            "             good    17.700439\n",
            "             nice    17.676976\n",
            " won disappointed    17.614909\n",
            "       just right    16.834990\n",
            "        wonderful    16.609821\n",
            "         favorite    16.541230\n",
            "          awesome    16.080359\n",
            "          amazing    16.005632\n",
            "             beat    15.131503\n",
            "        fantastic    14.650764\n",
            "              bit    14.377985\n",
            "\n",
            "-Top 20 negative-\n",
            "           Word  Coefficient\n",
            "  great reviews   -13.259437\n",
            "          gross   -13.325364\n",
            "          nasty   -13.580610\n",
            "     disgusting   -14.716671\n",
            "           weak   -15.146275\n",
            "  unfortunately   -15.290558\n",
            " disappointment   -15.488283\n",
            "           yuck   -15.509371\n",
            "         return   -15.634543\n",
            "    undrinkable   -15.788365\n",
            "      tasteless   -15.793533\n",
            "    waste money   -15.928341\n",
            "          stale   -16.648232\n",
            "          threw   -16.856784\n",
            "  disappointing   -18.056635\n",
            "   disappointed   -18.126238\n",
            "       horrible   -18.888690\n",
            "       terrible   -20.219614\n",
            "          awful   -20.910115\n",
            "          worst   -23.972405\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugzEMfTOZ5bR"
      },
      "source": [
        "#n=16\n",
        "text_fit(X_big, y_big, test_text, test_score, tfidf_n, LogisticRegression())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kuk9G4bcIDll"
      },
      "source": [
        "X_down = df_positive_down.append(df_negative_down)\n",
        "X_up = df_positive_up.append(df_negative_up)\n",
        "y_down = np.zeros((len(df_negative_down)+len(df_positive_down),1))\n",
        "y_down[0:len(df_positive_down)] = 1\n",
        "y_up = np.zeros((len(df_negative_up)+len(df_positive_up),1))\n",
        "y_up[0:len(df_positive_up)] = 1"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8to3Josljzs"
      },
      "source": [
        "n=1\n",
        "df_positive_up_big = df_positive_up.sample(n*len(df_positive_up), replace=True)\n",
        "df_negative_up_big = df_negative_up.sample(n*len(df_negative_up), replace=True)\n",
        "df_positive_down_big = df_positive_down.sample(n*len(df_positive_down), replace=True)\n",
        "df_negative_down_big = df_negative_down.sample(n*len(df_negative_down), replace=True)\n",
        "X_up_big = df_positive_up_big.append(df_negative_up_big)\n",
        "y_up_big = np.zeros((len(df_negative_up_big)+len(df_positive_up_big),1))\n",
        "y_up_big[0:len(df_positive_up_big)] = 1\n",
        "X_down_big = df_positive_down_big.append(df_negative_down_big)\n",
        "y_down_big = np.zeros((len(df_negative_down_big)+len(df_positive_down_big),1))\n",
        "y_down_big[0:len(df_positive_down_big)] = 1"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMYGBl0Klt-x",
        "outputId": "5b2c58cd-b3cd-4b1d-9707-c7b87e5f4c5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#n=4\n",
        "text_fit(X_up_big, y_up_big, test_text, test_score, tfidf_n, LogisticRegression())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# features: 3521186\n",
            "# train records: 2919192\n",
            "# test records: 142114\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model Training Accuracy: 0.9946516022241771\n",
            "Model Test Accuracy: 0.9446711794756323\n",
            "Confusion matrix [[ 17858   2738]\n",
            " [  5125 116393]]\n",
            "F1 Score: 0.8195690584914752\n",
            "Recall: 0.8670615653524957\n",
            "Precision: 0.7770090936779359\n",
            "\n",
            "-Top 20 positive-\n",
            "             Word  Coefficient\n",
            "            great    21.962996\n",
            "             best    20.638290\n",
            "        delicious    20.455408\n",
            "          perfect    19.175356\n",
            "            loves    16.938529\n",
            "        excellent    16.276780\n",
            " highly recommend    15.157621\n",
            "        wonderful    14.622828\n",
            "           hooked    13.870444\n",
            "          amazing    13.551968\n",
            "          awesome    13.070841\n",
            "             love    13.060740\n",
            "             good    12.716394\n",
            "             nice    12.480202\n",
            "       just right    12.363941\n",
            "          pleased    11.610963\n",
            "         favorite    11.533761\n",
            "        fantastic    11.528493\n",
            "            yummy    11.402195\n",
            "             glad    11.362790\n",
            "\n",
            "-Top 20 negative-\n",
            "           Word  Coefficient\n",
            "          worse   -12.666410\n",
            "           poor   -12.940237\n",
            "    waste money   -13.093947\n",
            "           weak   -13.267240\n",
            "  unfortunately   -13.478394\n",
            "          nasty   -13.506595\n",
            "          gross   -13.673763\n",
            "           yuck   -14.154697\n",
            "         return   -14.426382\n",
            "          stale   -14.597274\n",
            "     disgusting   -15.717415\n",
            " disappointment   -16.152835\n",
            "      tasteless   -16.200696\n",
            "          threw   -16.536562\n",
            "       horrible   -17.766600\n",
            "  disappointing   -19.738478\n",
            "   disappointed   -20.114292\n",
            "          awful   -20.687657\n",
            "       terrible   -21.372250\n",
            "          worst   -25.523929\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLBpj2rip6ci",
        "outputId": "16be7f2c-10f2-411e-ad48-c32d261aa45a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#n=6\n",
        "text_fit(X_up_big, y_up_big, test_text, test_score, tfidf_n, LogisticRegression())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# features: 3547293\n",
            "# train records: 4378788\n",
            "# test records: 142114\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model Training Accuracy: 0.996751384172972\n",
            "Model Test Accuracy: 0.9466203188989122\n",
            "Confusion matrix [[ 17685   2911]\n",
            " [  4675 116843]]\n",
            "F1 Score: 0.8234006890771952\n",
            "Recall: 0.8586618760924452\n",
            "Precision: 0.7909212880143113\n",
            "\n",
            "-Top 20 positive-\n",
            "             Word  Coefficient\n",
            "            great    22.641239\n",
            "             best    22.250721\n",
            "        delicious    22.100629\n",
            "          perfect    19.651206\n",
            "            loves    18.261304\n",
            "        excellent    17.663906\n",
            " highly recommend    16.936113\n",
            "           hooked    15.767885\n",
            "        wonderful    15.211198\n",
            "          amazing    14.969446\n",
            "          awesome    13.905995\n",
            "       just right    13.818796\n",
            "             love    13.499521\n",
            "             good    13.199401\n",
            "             nice    13.173813\n",
            " won disappointed    13.156027\n",
            "            yummy    12.871948\n",
            "        fantastic    12.489488\n",
            "          pleased    12.199450\n",
            "         favorite    12.094527\n",
            "\n",
            "-Top 20 negative-\n",
            "           Word  Coefficient\n",
            "            rip   -13.624717\n",
            "           weak   -13.902542\n",
            "    waste money   -14.009959\n",
            "          worse   -14.081940\n",
            "  unfortunately   -14.126292\n",
            "          nasty   -14.321061\n",
            "          gross   -14.840847\n",
            "         return   -15.622846\n",
            "           yuck   -15.839886\n",
            "          stale   -15.952373\n",
            "     disgusting   -17.580829\n",
            "      tasteless   -17.969971\n",
            "          threw   -18.576504\n",
            " disappointment   -18.858004\n",
            "       horrible   -19.230154\n",
            "   disappointed   -21.141152\n",
            "  disappointing   -21.881571\n",
            "          awful   -22.377374\n",
            "       terrible   -23.282707\n",
            "          worst   -28.859596\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4t9s4U2l370j",
        "outputId": "8253e61e-df11-44ea-adc4-3df1da85d8f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#n=8\n",
        "text_fit(X_up_big, y_up_big, test_text, test_score, tfidf_n, LogisticRegression())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# features: 3551440\n",
            "# train records: 5838384\n",
            "# test records: 142114\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model Training Accuracy: 0.998020685175898\n",
            "Model Test Accuracy: 0.9477813586275807\n",
            "Confusion matrix [[ 17589   3007]\n",
            " [  4414 117104]]\n",
            "F1 Score: 0.8257940327237729\n",
            "Recall: 0.8540007768498737\n",
            "Precision: 0.7993909921374358\n",
            "\n",
            "-Top 20 positive-\n",
            "             Word  Coefficient\n",
            "            great    23.829698\n",
            "             best    22.932495\n",
            "        delicious    22.303568\n",
            "          perfect    21.216298\n",
            "            loves    18.921283\n",
            "        excellent    17.811063\n",
            " highly recommend    17.728594\n",
            "           hooked    16.108067\n",
            "        wonderful    15.942163\n",
            "          amazing    15.563808\n",
            "          awesome    14.536647\n",
            "             love    14.156905\n",
            "       just right    14.133120\n",
            "             good    14.023967\n",
            "             nice    13.886421\n",
            " won disappointed    13.821081\n",
            "          pleased    12.960343\n",
            "        fantastic    12.899619\n",
            "            yummy    12.770920\n",
            "         downside    12.581235\n",
            "\n",
            "-Top 20 negative-\n",
            "           Word  Coefficient\n",
            "  unfortunately   -14.222411\n",
            "           poor   -14.413819\n",
            "    waste money   -14.596950\n",
            "           weak   -14.649148\n",
            "          worse   -14.832728\n",
            "          nasty   -15.377134\n",
            "          gross   -15.552763\n",
            "           yuck   -16.182413\n",
            "          stale   -16.419692\n",
            "         return   -16.620286\n",
            "     disgusting   -17.831021\n",
            "      tasteless   -18.705315\n",
            " disappointment   -19.137540\n",
            "          threw   -19.242576\n",
            "       horrible   -20.493231\n",
            "   disappointed   -22.131073\n",
            "  disappointing   -22.561893\n",
            "          awful   -23.869868\n",
            "       terrible   -24.387733\n",
            "          worst   -29.156826\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCvg75iMDAcs",
        "outputId": "8b0af46b-b56b-496b-9776-a3420f1151ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#n=10 down\n",
        "text_fit(X_down_big, y_down_big, test_text, test_score, tfidf_n, LogisticRegression())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# features: 1632872\n",
            "# train records: 1228820\n",
            "# test records: 142114\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model Training Accuracy: 0.9967212447714067\n",
            "Model Test Accuracy: 0.9108532586515051\n",
            "Confusion matrix [[ 18855   1741]\n",
            " [ 10928 110590]]\n",
            "F1 Score: 0.748526171619127\n",
            "Recall: 0.9154690231112838\n",
            "Precision: 0.6330792734110062\n",
            "\n",
            "-Top 20 positive-\n",
            "             Word  Coefficient\n",
            "            great    23.284070\n",
            "             best    20.504184\n",
            "        delicious    20.192314\n",
            "          perfect    17.985714\n",
            "            loves    16.095251\n",
            "        excellent    15.819308\n",
            "             love    14.426159\n",
            "        wonderful    13.495235\n",
            " highly recommend    12.872426\n",
            "         favorite    12.801760\n",
            "             good    12.597622\n",
            "             nice    12.512296\n",
            "          amazing    12.071739\n",
            "           hooked    11.535581\n",
            "          awesome    11.499417\n",
            "           highly    10.794829\n",
            "            thank    10.769232\n",
            "       just right    10.674564\n",
            "            yummy    10.664066\n",
            "          pleased    10.643701\n",
            "\n",
            "-Top 20 negative-\n",
            "           Word  Coefficient\n",
            "          waste   -10.108279\n",
            "          nasty   -10.198762\n",
            "          bland   -10.232369\n",
            "          gross   -10.502763\n",
            "          sorry   -10.609181\n",
            "          money   -11.182166\n",
            "         return   -11.324937\n",
            "           weak   -11.568032\n",
            "      tasteless   -11.635711\n",
            "          stale   -12.060556\n",
            "     disgusting   -12.085967\n",
            "  unfortunately   -12.693242\n",
            " disappointment   -12.941054\n",
            "          threw   -12.968894\n",
            "       horrible   -14.417589\n",
            "          awful   -16.745479\n",
            "       terrible   -16.806164\n",
            "  disappointing   -17.724885\n",
            "   disappointed   -19.038541\n",
            "          worst   -19.574536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHyJHja2FgJZ",
        "outputId": "1e7dfdd1-64ef-4fe4-f39b-a07521b80506",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#n=20 down\n",
        "text_fit(X_down_big, y_down_big, test_text, test_score, tfidf_n, LogisticRegression())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# features: 1632982\n",
            "# train records: 2457640\n",
            "# test records: 142114\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model Training Accuracy: 0.9995992089972494\n",
            "Model Test Accuracy: 0.9119017127095149\n",
            "Confusion matrix [[ 18844   1752]\n",
            " [ 10768 110750]]\n",
            "F1 Score: 0.7506373486297004\n",
            "Recall: 0.9149349388230724\n",
            "Precision: 0.6363636363636364\n",
            "\n",
            "-Top 20 positive-\n",
            "             Word  Coefficient\n",
            "            great    25.955155\n",
            "             best    23.482807\n",
            "        delicious    22.869613\n",
            "          perfect    20.775217\n",
            "            loves    18.871484\n",
            "        excellent    18.040395\n",
            "             love    15.703490\n",
            " highly recommend    15.662180\n",
            "        wonderful    15.565371\n",
            "          amazing    14.780255\n",
            "         favorite    14.643784\n",
            "             good    14.251769\n",
            "             nice    14.190326\n",
            "           hooked    14.133811\n",
            "          awesome    13.928174\n",
            "            yummy    12.862188\n",
            " won disappointed    12.767706\n",
            "          pleased    12.695205\n",
            "       just right    12.628876\n",
            "            thank    12.439287\n",
            "\n",
            "-Top 20 negative-\n",
            "           Word  Coefficient\n",
            "          nasty   -12.245782\n",
            "           poor   -12.288928\n",
            "         refund   -12.363276\n",
            "          gross   -12.586327\n",
            "          sorry   -12.658145\n",
            "          money   -12.870779\n",
            "         return   -13.216665\n",
            "           weak   -13.247866\n",
            "          stale   -13.900971\n",
            "  unfortunately   -14.101178\n",
            "      tasteless   -14.453405\n",
            "     disgusting   -14.498802\n",
            "          threw   -15.389161\n",
            " disappointment   -15.888594\n",
            "       horrible   -16.922366\n",
            "          awful   -20.023891\n",
            "       terrible   -20.362940\n",
            "  disappointing   -21.701177\n",
            "   disappointed   -21.784993\n",
            "          worst   -24.044609\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IBxjoRYJ_wF",
        "outputId": "0bebb322-6df6-4468-8c18-82258fee7403",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#n=40 down\n",
        "text_fit(X_down_big, y_down_big, test_text, test_score, tfidf_n, LogisticRegression())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# features: 1632982\n",
            "# train records: 4915280\n",
            "# test records: 142114\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model Training Accuracy: 0.9999035660226885\n",
            "Model Test Accuracy: 0.9122465063259074\n",
            "Confusion matrix [[ 18852   1744]\n",
            " [ 10727 110791]]\n",
            "F1 Score: 0.7514499252615844\n",
            "Recall: 0.9153233637599534\n",
            "Precision: 0.6373440616653707\n",
            "\n",
            "-Top 20 positive-\n",
            "             Word  Coefficient\n",
            "            great    28.932181\n",
            "             best    26.045913\n",
            "        delicious    25.990652\n",
            "          perfect    22.923824\n",
            "            loves    20.824153\n",
            "        excellent    20.635775\n",
            "             love    17.588041\n",
            "        wonderful    17.390358\n",
            " highly recommend    17.193421\n",
            "         favorite    16.225820\n",
            "          amazing    16.136321\n",
            "             good    15.961379\n",
            "           hooked    15.691404\n",
            "             nice    15.689290\n",
            "          awesome    15.012204\n",
            " won disappointed    14.375725\n",
            "       just right    14.132111\n",
            "            yummy    13.952019\n",
            "          pleased    13.872452\n",
            "            thank    13.601920\n",
            "\n",
            "-Top 20 negative-\n",
            "           Word  Coefficient\n",
            "         refund   -13.433673\n",
            "          worse   -13.477998\n",
            "           poor   -13.533635\n",
            "          gross   -13.776882\n",
            "          sorry   -14.075319\n",
            "          money   -14.084695\n",
            "         return   -14.189625\n",
            "           weak   -14.833015\n",
            "          stale   -15.776391\n",
            "     disgusting   -15.850629\n",
            "      tasteless   -16.030335\n",
            "  unfortunately   -16.364155\n",
            "          threw   -17.000986\n",
            " disappointment   -17.355267\n",
            "       horrible   -18.746747\n",
            "          awful   -21.746071\n",
            "       terrible   -22.293197\n",
            "  disappointing   -23.817680\n",
            "   disappointed   -24.125046\n",
            "          worst   -26.328279\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDSpSuH_CNjp",
        "outputId": "b9150113-11a9-49ac-9f16-0fa6491311b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "text_fit(X, y, c, DummyClassifier(),0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# features: 119939\n",
            "# train records: 426340\n",
            "# test records: 142114\n",
            "Model Accuracy: 0.7518752550769101\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tr1nZiEiCUzi",
        "outputId": "fde27b32-6772-42d8-fa0b-56453f6f1dd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tfidf = TfidfVectorizer(stop_words = 'english')\n",
        "text_fit(X, y, tfidf, LogisticRegression())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# features: 119939\n",
            "# train records: 426340\n",
            "# test records: 142114\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model Accuracy: 0.9224284729161096\n",
            "\n",
            "-Top 20 positive-\n",
            "       Word  Coefficient\n",
            "      great    11.940613\n",
            "  delicious    10.551228\n",
            "       best    10.147604\n",
            "    perfect     9.368369\n",
            "      loves     8.790815\n",
            "  excellent     8.406053\n",
            "     highly     7.841667\n",
            "       love     7.580810\n",
            "     hooked     6.980460\n",
            "  wonderful     6.808297\n",
            "       good     6.584383\n",
            "       nice     6.509065\n",
            "    amazing     6.418014\n",
            " pleasantly     6.317414\n",
            "    awesome     6.245800\n",
            "   favorite     6.183629\n",
            "  fantastic     5.851168\n",
            "      yummy     5.821420\n",
            "       beat     5.544562\n",
            "       easy     5.522370\n",
            "\n",
            "-Top 20 negative-\n",
            "           Word  Coefficient\n",
            "          worse    -5.023784\n",
            "        useless    -5.251663\n",
            "  unfortunately    -5.315098\n",
            "          nasty    -5.479692\n",
            "          gross    -5.563191\n",
            "         return    -5.592826\n",
            "           poor    -5.662447\n",
            "          waste    -5.801514\n",
            "    undrinkable    -6.029512\n",
            "           yuck    -6.084586\n",
            "      tasteless    -6.268094\n",
            "     disgusting    -6.297766\n",
            "          threw    -6.514589\n",
            " disappointment    -6.764485\n",
            "   disappointed    -6.832450\n",
            "       horrible    -7.340662\n",
            "  disappointing    -7.696213\n",
            "          awful    -8.197432\n",
            "       terrible    -8.594562\n",
            "          worst   -10.376968\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSH9SB5ZClkG",
        "outputId": "1dcbfd1c-8918-4f8c-a326-312bc0bbd27d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "tfidf = TfidfVectorizer(stop_words = 'english')\n",
        "tfidf_n = TfidfVectorizer(ngram_range=(1,2),stop_words = 'english')\n",
        "text_fit(train_text, train_score, test_text, test_score, tfidf, RandomForestClassifier(), coef_show = 0)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# features: 106996\n",
            "# train records: 426340\n",
            "# test records: 142114\n",
            "Model Training Accuracy: 0.9996669324951917\n",
            "Model Test Accuracy: 0.9257497502005432\n",
            "Confusion matrix [[ 10261  10335]\n",
            " [   217 121301]]\n",
            "F1 Score: 0.6604235051811804\n",
            "Recall: 0.49820353466692563\n",
            "Precision: 0.9792899408284024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-96aa8ec64f23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtfidf_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstop_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtext_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-dc6ff14cafb4>\u001b[0m in \u001b[0;36mtext_fit\u001b[0;34m(X_train, y_train, X_test, y_test, model, clf_model, coef_show)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcoef_show\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mcoef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mcoeff_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Word'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Coefficient'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mcoef\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mcoeff_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoeff_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Coefficient'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Word'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'RandomForestClassifier' object has no attribute 'coef_'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzEYmCJj3J4s",
        "outputId": "2b4bb392-11d8-4383-c826-a2a0e4ea11c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_score.sum()/train_score.count()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8558873199793592"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQuaxMGNIJhk",
        "outputId": "866c0ebe-d0b6-4ab6-d1b0-7c7b03416c90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "text_fit(X_down, y_down, test_text, test_score, tfidf, RandomForestClassifier(), coef_show = 0)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# features: 61381\n",
            "# train records: 122882\n",
            "# test records: 142114\n",
            "Model Training Accuracy: 0.9990234533943132\n",
            "Model Test Accuracy: 0.8917066580350986\n",
            "Confusion matrix [[ 18246   2350]\n",
            " [ 13040 108478]]\n",
            "F1 Score: 0.7033653290158436\n",
            "Recall: 0.8859001747912216\n",
            "Precision: 0.5832001534232564\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVIupd4P5FwM",
        "outputId": "9d69c546-e678-4735-e1dc-72d64d3d0393",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "text_fit(train_text, train_score, test_text, test_score, tfidf, XGBClassifier(), coef_show = 0)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# features: 106996\n",
            "# train records: 426340\n",
            "# test records: 142114\n",
            "Model Training Accuracy: 0.874829947928883\n",
            "Model Test Accuracy: 0.8740447809505045\n",
            "Confusion matrix [[  3014  17582]\n",
            " [   318 121200]]\n",
            "F1 Score: 0.25192243396857233\n",
            "Recall: 0.14633909496989705\n",
            "Precision: 0.904561824729892\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0Vad2if5Lrw",
        "outputId": "2374fb53-e2b7-4d11-cca0-c10c2635df46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "text_fit(X_up, y_up, test_text, test_score, tfidf, XGBClassifier(), coef_show = 0)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# features: 106971\n",
            "# train records: 729798\n",
            "# test records: 142114\n",
            "Model Training Accuracy: 0.7774466359184322\n",
            "Model Test Accuracy: 0.745929324345244\n",
            "Confusion matrix [[16960  3636]\n",
            " [32471 89047]]\n",
            "F1 Score: 0.4843845945135447\n",
            "Recall: 0.8234608661876093\n",
            "Precision: 0.34310452954623616\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7x677Wrs-16a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}