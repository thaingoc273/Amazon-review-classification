{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_LSTM_Amazon_Reviews.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IItR64mTCvE-",
        "outputId": "2012c9bf-f137-4aa6-f946-3b381223b114",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pfCTaIYDB4N",
        "outputId": "4e976119-2385-4804-be9e-f49fb53bab37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from tqdm import tqdm\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,f1_score, confusion_matrix, recall_score, precision_score\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense , Input , LSTM , Embedding, Dropout , Activation, GRU, Flatten\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Convolution1D\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZXmfLIMDlhE"
      },
      "source": [
        "save_path = '/content/drive/My Drive/Natural Language Processing/Reviews.csv'\n",
        "df = pd.read_csv(save_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpFvWIUvDwI2"
      },
      "source": [
        "df[\"Label\"] = df[\"Score\"].apply(lambda x : 1 if x>=3 else 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrA5l-CpD0-D",
        "outputId": "3f6efbdc-647f-4c1c-ad38-237e94bf719e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "final_df=df.drop_duplicates(subset={\"Score\",\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep='first', inplace=False)\n",
        "final_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(394008, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgzi3kFQw_Fk"
      },
      "source": [
        "def decontract(text):\n",
        "    text = re.sub(r\"won\\'t\", \"will not\", text)\n",
        "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
        "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"\\'s\", \" is\", text)\n",
        "    text = re.sub(r\"\\'d\", \" would\", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "    text = re.sub(r\"\\'t\", \" not\", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "    text = re.sub(r\"\\'m\", \" am\", text)\n",
        "    return text\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3JwxWG8xB82"
      },
      "source": [
        "#set of custom stop words\n",
        "stop_words= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
        "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
        "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
        "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
        "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
        "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
        "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
        "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
        "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
        "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
        "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
        "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
        "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
        "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
        "            'won', \"won't\", 'wouldn', \"wouldn't\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MBX3FAFxHWD",
        "outputId": "370c3f2b-1433-42ce-f464-2de4b0cc9eeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "import nltk\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FX8u3x6xP2z"
      },
      "source": [
        "def preprocess_text(review):\n",
        "    review = re.sub(r\"http\\S+\", \"\", review)             # removing website links\n",
        "    review = BeautifulSoup(review, 'lxml').get_text()   # removing html tags\n",
        "    review = decontract(review)                         # decontracting\n",
        "    review = re.sub(\"\\S*\\d\\S*\", \"\", review).strip()     # removing the words with numeric digits\n",
        "    review = re.sub('[^A-Za-z]+', ' ', review)          # removing non-word characters\n",
        "    review = review.lower()                             # converting to lower case\n",
        "    review = [word for word in review.split(\" \") if not word in stop_words] # removing stop words\n",
        "    review = [lemmatizer.lemmatize(token, \"v\") for token in review] #Lemmatization\n",
        "    review = \" \".join(review)\n",
        "    review.strip()\n",
        "    return review\n",
        "final_df['Text'] = final_df['Text'].apply(lambda x: preprocess_text(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf55At3Syr5I",
        "outputId": "5598b2a5-adf3-4287-87e8-e023c4ed2dc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "final_df['Text'] "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         I have bought several of the Vitality canned d...\n",
              "1         Product arrived labeled as Jumbo Salted Peanut...\n",
              "2         This is a confection that has been around a fe...\n",
              "3         If you are looking for the secret ingredient i...\n",
              "4         Great taffy at a great price.  There was a wid...\n",
              "                                ...                        \n",
              "568449    Great for sesame chicken..this is a good if no...\n",
              "568450    I'm disappointed with the flavor. The chocolat...\n",
              "568451    These stars are small, so you can give 10-15 o...\n",
              "568452    These are the BEST treats for training and rew...\n",
              "568453    I am very satisfied ,product is as advertised,...\n",
              "Name: Text, Length: 394008, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPtWgsM_D_z7",
        "outputId": "2c6cd0ec-7a86-4ae8-e07c-167f7a2df895",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "train_df, test_df = train_test_split(final_df, test_size = 0.1, random_state = 42)\n",
        "print(\"Training data size : \", train_df.shape)\n",
        "print(\"Test data size : \", test_df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data size :  (354607, 11)\n",
            "Test data size :  (39401, 11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c52z9bcvd00"
      },
      "source": [
        "train_text = train_df[\"Text\"]\n",
        "train_score = train_df[\"Label\"]\n",
        "\n",
        "test_text = test_df[\"Text\"]\n",
        "test_score = test_df[\"Label\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTNvxOF_wKDh"
      },
      "source": [
        "df_positive = train_df[train_df[\"Label\"]==1]\n",
        "df_negative = train_df[train_df[\"Label\"]==0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfWDXxSnwUo0"
      },
      "source": [
        "df_positive_text = df_positive[\"Text\"]\n",
        "df_negative_text = df_negative[\"Text\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvqWIjiCwcWq"
      },
      "source": [
        "df_negative_up = df_negative_text.sample(len(df_positive_text), replace=True)\n",
        "df_positive_up = df_positive_text\n",
        "df_positive_down = df_positive_text.sample(len(df_negative_text))\n",
        "df_negative_down = df_negative_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kG6As_AwiLM"
      },
      "source": [
        "n=2\n",
        "df_negative_big = df_negative_text.sample(n*len(df_negative_text), replace = True)\n",
        "df_positive_big = df_positive_text.sample(n*len(df_positive_text), replace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zxdYovxwjgT"
      },
      "source": [
        "X_big = df_positive_big.append(df_negative_big)\n",
        "y_big = np.zeros((len(X_big),1))\n",
        "l = len(df_positive_big)\n",
        "y_big[0:l] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzL7ks6hwt-8",
        "outputId": "3e558813-be41-41a5-bfa2-27d485af911c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "print(len(df_negative_up))\n",
        "print(len(df_positive_up))\n",
        "print(len(df_negative_down))\n",
        "print(len(df_positive_down))\n",
        "print(len(df_negative_big))\n",
        "print(len(df_positive_big))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "303128\n",
            "303128\n",
            "51479\n",
            "51479\n",
            "102958\n",
            "606256\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQtQ1huexCL7",
        "outputId": "699c1125-b91a-428e-8ebf-e9052b130951",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        }
      },
      "source": [
        "X_down = df_positive_down.append(df_negative_down)\n",
        "X_up = df_positive_up.append(df_negative_up)\n",
        "y_down = np.zeros((len(df_negative_down)+len(df_positive_down),1))\n",
        "y_down[0:len(df_positive_down)] = 1\n",
        "y_up = np.zeros((len(df_negative_up)+len(df_positive_up),1))\n",
        "y_up[0:len(df_positive_up)] = 1\n",
        "print(y_down)\n",
        "print(y_up)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " ...\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]]\n",
            "[[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " ...\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iJ0AlcDxPgp"
      },
      "source": [
        "top_words = 10000\n",
        "tokenizer = Tokenizer(num_words=top_words)\n",
        "tokenizer.fit_on_texts(train_df['Text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkjbkUJyxv3k",
        "outputId": "5e452e48-5fb0-4db2-af4c-3f76f524809a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "X_up"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "257779    I am very happy with this wine in a box kit. S...\n",
              "81168     For some reason, they sent me the \"mini\" small...\n",
              "361298    <a href=\"http://www.amazon.com/gp/product/B003...\n",
              "22075     The toy got a lot of interest, but I eventuall...\n",
              "119395    I'm so glad to see this on Amazon!  I first bo...\n",
              "                                ...                        \n",
              "99491     It does not taste bad, but I thought I was pur...\n",
              "418958    I totally agreed with all of you who bought th...\n",
              "501061    I bought this product three times. The first t...\n",
              "315952    They show you a picture of the good opaque whi...\n",
              "136101    Many people seem to love this tea, but it wasn...\n",
              "Name: Text, Length: 606256, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sv1O6AZXEIOE"
      },
      "source": [
        "list_tokenized_train = tokenizer.texts_to_sequences(train_df['Text'])\n",
        "max_review_length = 50\n",
        "X_train = pad_sequences(list_tokenized_train, maxlen=max_review_length)\n",
        "y_train = train_df['Label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jY1ZeaOBFciX",
        "outputId": "42ab0dc7-b4e1-4255-a39c-21b7944e6cf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "list_tokenized_train[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4,\n",
              " 408,\n",
              " 395,\n",
              " 391,\n",
              " 62,\n",
              " 278,\n",
              " 403,\n",
              " 34,\n",
              " 430,\n",
              " 2484,\n",
              " 103,\n",
              " 123,\n",
              " 434,\n",
              " 1243,\n",
              " 104,\n",
              " 431,\n",
              " 565,\n",
              " 196,\n",
              " 7,\n",
              " 761,\n",
              " 4,\n",
              " 2,\n",
              " 55,\n",
              " 1,\n",
              " 430,\n",
              " 2484,\n",
              " 103,\n",
              " 123,\n",
              " 2739,\n",
              " 23,\n",
              " 242,\n",
              " 96,\n",
              " 56,\n",
              " 1,\n",
              " 60,\n",
              " 1621,\n",
              " 31,\n",
              " 3564,\n",
              " 8660,\n",
              " 2,\n",
              " 17,\n",
              " 92,\n",
              " 23,\n",
              " 21,\n",
              " 1466,\n",
              " 11,\n",
              " 33,\n",
              " 3,\n",
              " 1264,\n",
              " 3,\n",
              " 1855,\n",
              " 2,\n",
              " 92,\n",
              " 4,\n",
              " 318,\n",
              " 3267,\n",
              " 2146,\n",
              " 5,\n",
              " 414,\n",
              " 16,\n",
              " 902,\n",
              " 3,\n",
              " 1731,\n",
              " 7,\n",
              " 434,\n",
              " 2,\n",
              " 150,\n",
              " 40,\n",
              " 1,\n",
              " 208,\n",
              " 474,\n",
              " 1327,\n",
              " 3,\n",
              " 58,\n",
              " 1611,\n",
              " 2,\n",
              " 426,\n",
              " 1,\n",
              " 2739,\n",
              " 5,\n",
              " 1,\n",
              " 521,\n",
              " 12,\n",
              " 2117,\n",
              " 33,\n",
              " 3,\n",
              " 1264,\n",
              " 23,\n",
              " 21,\n",
              " 99,\n",
              " 212,\n",
              " 5,\n",
              " 87,\n",
              " 11,\n",
              " 13,\n",
              " 798,\n",
              " 11,\n",
              " 1,\n",
              " 283,\n",
              " 9,\n",
              " 8,\n",
              " 4,\n",
              " 39,\n",
              " 580,\n",
              " 32,\n",
              " 4,\n",
              " 5737,\n",
              " 83]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tusF6EIxcWb"
      },
      "source": [
        "list_tokenized_train_up = tokenizer.texts_to_sequences(X_up)\n",
        "max_review_length = 50\n",
        "X_train_up = pad_sequences(list_tokenized_train_up, maxlen=max_review_length)\n",
        "y_train_up = y_up"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVSMk90SFVC1",
        "outputId": "b2f73a3b-9cac-49e1-e539-8ece262b8ea6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "embedding_vetor_length = 32\n",
        "model = Sequential()\n",
        "model.add(Embedding(top_words+1, embedding_vetor_length, input_length=max_review_length))\n",
        "model.add(LSTM(50, return_sequences=True))\n",
        "model.add(LSTM(50, return_sequences=True))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 50, 32)            320032    \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (None, 50, 50)            16600     \n",
            "_________________________________________________________________\n",
            "lstm_8 (LSTM)                (None, 50, 50)            20200     \n",
            "_________________________________________________________________\n",
            "lstm_9 (LSTM)                (None, 50)                20200     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 377,083\n",
            "Trainable params: 377,083\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEolEs3936xn"
      },
      "source": [
        "model.load_weights('/content/drive/My Drive/Natural Language Processing/coef.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "893p4oGFFZtv",
        "outputId": "753fca95-02cf-4fbf-f5f7-251ec7d62c6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        }
      },
      "source": [
        "model.fit(X_train,y_train, nb_epoch=10, batch_size=512, validation_split=0.1)\n",
        "model.save('/content/drive/My Drive/Natural Language Processing/coef.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 319146 samples, validate on 35461 samples\n",
            "Epoch 1/10\n",
            "319146/319146 [==============================] - 440s 1ms/step - loss: 0.1316 - accuracy: 0.9459 - val_loss: 0.2130 - val_accuracy: 0.9173\n",
            "Epoch 2/10\n",
            "319146/319146 [==============================] - 442s 1ms/step - loss: 0.1205 - accuracy: 0.9506 - val_loss: 0.2217 - val_accuracy: 0.9137\n",
            "Epoch 3/10\n",
            "319146/319146 [==============================] - 447s 1ms/step - loss: 0.1097 - accuracy: 0.9556 - val_loss: 0.2486 - val_accuracy: 0.9139\n",
            "Epoch 4/10\n",
            "319146/319146 [==============================] - 454s 1ms/step - loss: 0.0997 - accuracy: 0.9604 - val_loss: 0.2522 - val_accuracy: 0.9113\n",
            "Epoch 5/10\n",
            "319146/319146 [==============================] - 458s 1ms/step - loss: 0.0907 - accuracy: 0.9642 - val_loss: 0.2811 - val_accuracy: 0.9112\n",
            "Epoch 6/10\n",
            " 98304/319146 [========>.....................] - ETA: 5:09 - loss: 0.0749 - accuracy: 0.9710"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-a403a8fdd5ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Natural Language Processing/coef.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfhhUxnw3awc"
      },
      "source": [
        "model.save('/content/drive/My Drive/Natural Language Processing/coef.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTsSsOL90fh1"
      },
      "source": [
        "model.load_weights('/content/drive/My Drive/Natural Language Processing/coef_up.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8XjC9YV0jXW",
        "outputId": "d3b4c8da-7b9c-4fe4-c897-fbd0d57fc1bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        }
      },
      "source": [
        "model.fit(X_train_up,y_train_up, nb_epoch=8, batch_size=512, validation_split=0.1)\n",
        "model.save('/content/drive/My Drive/Natural Language Processing/coef_up.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 545630 samples, validate on 60626 samples\n",
            "Epoch 1/8\n",
            "545630/545630 [==============================] - 762s 1ms/step - loss: 0.1301 - accuracy: 0.9547 - val_loss: 0.1396 - val_accuracy: 0.9592\n",
            "Epoch 2/8\n",
            "545630/545630 [==============================] - 737s 1ms/step - loss: 0.0991 - accuracy: 0.9667 - val_loss: 0.1209 - val_accuracy: 0.9673\n",
            "Epoch 3/8\n",
            "545630/545630 [==============================] - 735s 1ms/step - loss: 0.0809 - accuracy: 0.9736 - val_loss: 0.0983 - val_accuracy: 0.9723\n",
            "Epoch 4/8\n",
            "545630/545630 [==============================] - 731s 1ms/step - loss: 0.0683 - accuracy: 0.9785 - val_loss: 0.0750 - val_accuracy: 0.9835\n",
            "Epoch 5/8\n",
            "545630/545630 [==============================] - 768s 1ms/step - loss: 0.0585 - accuracy: 0.9821 - val_loss: 0.0663 - val_accuracy: 0.9849\n",
            "Epoch 6/8\n",
            "534016/545630 [============================>.] - ETA: 16s - loss: 0.0516 - accuracy: 0.9845"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-574aacf69c7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_up\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_up\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Natural Language Processing/coef_up.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyW7FHVfLaeq",
        "outputId": "d493d5c0-5703-469b-a98d-a0666f29b61f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "list_tokenized_test = tokenizer.texts_to_sequences(test_df['Text'])\n",
        "X_test = pad_sequences(list_tokenized_test, maxlen=max_review_length)\n",
        "y_test = test_df['Label']\n",
        "prediction = model.predict(X_test)\n",
        "y_pred = (prediction > 0.5)\n",
        "print(\"Accuracy of the model : \", accuracy_score(y_pred, y_test))\n",
        "print('F1-score: ', f1_score(y_test, y_pred, pos_label=0))\n",
        "recall_score_value = recall_score(y_test, y_pred, pos_label=0)\n",
        "precision_score_value = precision_score(y_test, y_pred, pos_label=0)\n",
        "print('Recall: {}'.format(recall_score_value))\n",
        "print('Precision: {}'.format(precision_score_value))\n",
        "print('Confusion matrix: {}'.format(confusion_matrix(y_test,y_pred)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the model :  0.9002817187381031\n",
            "F1-score:  0.6655316250957691\n",
            "Recall: 0.6930851063829787\n",
            "Precision: 0.6400851481906009\n",
            "Confusion matrix: [[ 3909  1731]\n",
            " [ 2198 31563]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFaU0vdVy0qH",
        "outputId": "c7970a7b-33ab-4e84-9260-fc4e42046a51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "# Test for model upsampling\n",
        "list_tokenized_test = tokenizer.texts_to_sequences(test_df['Text'])\n",
        "X_test = pad_sequences(list_tokenized_test, maxlen=max_review_length)\n",
        "y_test = test_df['Label']\n",
        "prediction = model.predict(X_test)\n",
        "y_pred = (prediction > 0.5)\n",
        "print(\"Accuracy of the model : \", accuracy_score(y_pred, y_test))\n",
        "print('F1-score: ', f1_score(y_test, y_pred, pos_label=0))\n",
        "recall_score_value = recall_score(y_test, y_pred, pos_label=0)\n",
        "precision_score_value = precision_score(y_test, y_pred, pos_label=0)\n",
        "print('Recall: {}'.format(recall_score_value))\n",
        "print('Precision: {}'.format(precision_score_value))\n",
        "print('Confusion matrix: {}'.format(confusion_matrix(y_test,y_pred)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the model :  0.9008654602675059\n",
            "F1-score:  0.6637975555173007\n",
            "Recall: 0.6836879432624113\n",
            "Precision: 0.6450317832050854\n",
            "Confusion matrix: [[ 3856  1784]\n",
            " [ 2122 31639]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pfPwmQWNysy",
        "outputId": "12c73a86-bbf6-477d-c00b-accf70f0613b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "source": [
        "embedding_vecor_length = 32\n",
        "model_1 = Sequential()\n",
        "model_1.add(Embedding(top_words+1, embedding_vecor_length, input_length=max_review_length))\n",
        "model_1.add(LSTM(100, return_sequences=True))\n",
        "model_1.add(LSTM(100))\n",
        "#model_1.add(Dense(50, activation='sigmoid'))\n",
        "model_1.add(Dense(1, activation='sigmoid'))\n",
        "model_1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 130, 32)           192032    \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 130, 100)          53200     \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 325,733\n",
            "Trainable params: 325,733\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQkuQbvOjCIh"
      },
      "source": [
        "model.load_weights('/content/drive/My Drive/Natural Language Processing/coef_1.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGhKXmuuN7rW",
        "outputId": "b3443b82-b829-44e9-e527-78ae4a6bbe7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "model_1.fit(X_train,y_train, nb_epoch=5, batch_size=2048, validation_split=0.05)\n",
        "model_1.save('/content/drive/My Drive/Natural Language Processing/coef_1.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 336876 samples, validate on 17731 samples\n",
            "Epoch 1/5\n",
            "336876/336876 [==============================] - 1585s 5ms/step - loss: 0.2039 - accuracy: 0.9158 - val_loss: 0.2112 - val_accuracy: 0.9138\n",
            "Epoch 2/5\n",
            "336876/336876 [==============================] - 1655s 5ms/step - loss: 0.1959 - accuracy: 0.9191 - val_loss: 0.2059 - val_accuracy: 0.9165\n",
            "Epoch 3/5\n",
            "336876/336876 [==============================] - 1639s 5ms/step - loss: 0.1883 - accuracy: 0.9218 - val_loss: 0.2052 - val_accuracy: 0.9160\n",
            "Epoch 4/5\n",
            "336876/336876 [==============================] - 1637s 5ms/step - loss: 0.1817 - accuracy: 0.9249 - val_loss: 0.2014 - val_accuracy: 0.9153\n",
            "Epoch 5/5\n",
            "336876/336876 [==============================] - 1642s 5ms/step - loss: 0.1742 - accuracy: 0.9277 - val_loss: 0.1990 - val_accuracy: 0.9168\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpUz6PueOEkl",
        "outputId": "aec83615-0ea2-47a5-922d-16ceb3395a73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "#list_tokenized_test = tokenizer.texts_to_sequences(test_df['Text'])\n",
        "#X_test = pad_sequences(list_tokenized_test, maxlen=max_review_length)\n",
        "#y_test = test_df['Label']\n",
        "prediction = model_1.predict(X_test)\n",
        "y_pred = (prediction > 0.5)\n",
        "print(\"Accuracy of the model : \", accuracy_score(y_pred, y_test))\n",
        "print('F1-score: ', f1_score(y_test, y_pred, pos_label=0))\n",
        "recall_score_value = recall_score(y_test, y_pred, pos_label=0)\n",
        "precision_score_value = precision_score(y_test, y_pred, pos_label=0)\n",
        "print('Recall: {}'.format(recall_score_value))\n",
        "print('Precision: {}'.format(precision_score_value))\n",
        "print('Confusion matrix: {}'.format(confusion_matrix(y_test,y_pred)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the model :  0.9186568868810436\n",
            "F1-score:  0.6818226943313809\n",
            "Recall: 0.6088652482269503\n",
            "Precision: 0.774644710128581\n",
            "Confusion matrix: [[ 3434  2206]\n",
            " [  999 32762]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}